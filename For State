from warnings import simplefilter
simplefilter(action='ignore', category=FutureWarning)
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline
import pandas as pd
import mglearn
from IPython.display import display
from sklearn.model_selection import train_test_split

#####################################################FIRST PROMPT
data = pd.read_excel(r'C:\Users\Akrilon\Desktop\energy2.xlsx')
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.preprocessing import PolynomialFeatures
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor


# Split data into train and test sets
X = data['Статьи баланса'].values.reshape(-1, 1)
y = data['Производство'].values.reshape(-1, 1)

# Define number of folds
n_folds = 5

# Initialize models
poly = PolynomialFeatures(degree=3)
poly_reg = LinearRegression()
tree_reg = DecisionTreeRegressor(random_state=42)
forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)

# Evaluate models with k-fold cross-validation
for model, name in zip([poly_reg, tree_reg, forest_reg], ['Полиномиальная регрессия', 'Дерево решений', 'Метод случайного леса']):
    scores = []
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    for train_idx, test_idx in kf.split(X):
        X_train, y_train = X[train_idx], y[train_idx]
        X_test, y_test = X[test_idx], y[test_idx]
        if model == poly_reg:
            X_train_poly = poly.fit_transform(X_train)
            model.fit(X_train_poly, y_train)
            score = model.score(poly.fit_transform(X_test), y_test)
        else:
            model.fit(X_train, y_train.ravel())
            score = model.score(X_test, y_test)
        scores.append(score)
    print(name)
    print('Среднее значение R^2: {:.2f}'.format(np.mean(scores)))
    print('Стандартное отклонение R^2: {:.2f}'.format(np.std(scores)))
    print()
X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
plt.scatter(X_train, y_train, color='red', label='Обучающий набор')
plt.scatter(X_test, y_test, color='blue', label='Тестовый набор')
plt.plot(X_plot, poly_reg.predict(poly.fit_transform(X_plot)), color='green', label='Полиномиальная регрессия')
plt.plot(X_plot, tree_reg.predict(X_plot), color='orange', label='Дерево решений')
plt.plot(X_plot, forest_reg.predict(X_plot), color='purple', label='Метод случайного леса')
plt.legend()
plt.show()


#########################################################SECOND PROMPT
data = pd.read_excel(r'C:\Users\Akrilon\Desktop\energy.xlsx')
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.preprocessing import PolynomialFeatures
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor


# Split data into train and test sets
X = data['Статья баланса'].values.reshape(-1, 1)
y = data['Производство-брутто, всего'].values.reshape(-1, 1)

# Define number of folds
n_folds = 5

# Initialize models
poly = PolynomialFeatures(degree=3)
poly_reg = LinearRegression()
tree_reg = DecisionTreeRegressor(random_state=42)
forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)

# Evaluate models with k-fold cross-validation
for model, name in zip([poly_reg, tree_reg, forest_reg], ['Полиномиальная регрессия', 'Дерево решений', 'Метод случайного леса']):
    scores = []
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    for train_idx, test_idx in kf.split(X):
        X_train, y_train = X[train_idx], y[train_idx]
        X_test, y_test = X[test_idx], y[test_idx]
        if model == poly_reg:
            X_train_poly = poly.fit_transform(X_train)
            model.fit(X_train_poly, y_train)
            score = model.score(poly.fit_transform(X_test), y_test)
        else:
            model.fit(X_train, y_train.ravel())
            score = model.score(X_test, y_test)
        scores.append(score)
    print(name)
    print('Среднее значение R^2: {:.2f}'.format(np.mean(scores)))
    print('Стандартное отклонение R^2: {:.2f}'.format(np.std(scores)))
    print()
X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
plt.scatter(X_train, y_train, color='red', label='Обучающий набор')
plt.scatter(X_test, y_test, color='blue', label='Тестовый набор')
plt.plot(X_plot, poly_reg.predict(poly.fit_transform(X_plot)), color='green', label='Полиномиальная регрессия')
plt.plot(X_plot, tree_reg.predict(X_plot), color='orange', label='Дерево решений')
plt.plot(X_plot, forest_reg.predict(X_plot), color='purple', label='Метод случайного леса')
plt.legend()
plt.show()

########################################################THIRD PROMPT
data = pd.read_excel(r'C:\Users\Akrilon\Desktop\energy3.xlsx')
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.preprocessing import PolynomialFeatures
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor


# Split data into train and test sets
X = data['Статья баланса'].values.reshape(-1, 1)
y = data['Производство-брутто, всего'].values.reshape(-1, 1)

# Define number of folds
n_folds = 5

# Initialize models
poly = PolynomialFeatures(degree=3)
poly_reg = LinearRegression()
tree_reg = DecisionTreeRegressor(random_state=42)
forest_reg = RandomForestRegressor(n_estimators=100, random_state=42)

# Evaluate models with k-fold cross-validation
for model, name in zip([poly_reg, tree_reg, forest_reg], ['Полиномиальная регрессия', 'Дерево решений', 'Метод случайного леса']):
    scores = []
    kf = KFold(n_splits=n_folds, shuffle=True, random_state=42)
    for train_idx, test_idx in kf.split(X):
        X_train, y_train = X[train_idx], y[train_idx]
        X_test, y_test = X[test_idx], y[test_idx]
        if model == poly_reg:
            X_train_poly = poly.fit_transform(X_train)
            model.fit(X_train_poly, y_train)
            score = model.score(poly.fit_transform(X_test), y_test)
        else:
            model.fit(X_train, y_train.ravel())
            score = model.score(X_test, y_test)
        scores.append(score)
    print(name)
    print('Среднее значение R^2: {:.2f}'.format(np.mean(scores)))
    print('Стандартное отклонение R^2: {:.2f}'.format(np.std(scores)))
    print()
X_plot = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
plt.scatter(X_train, y_train, color='red', label='Обучающий набор')
plt.scatter(X_test, y_test, color='blue', label='Тестовый набор')
plt.plot(X_plot, poly_reg.predict(poly.fit_transform(X_plot)), color='green', label='Полиномиальная регрессия')
plt.plot(X_plot, tree_reg.predict(X_plot), color='orange', label='Дерево решений')
plt.plot(X_plot, forest_reg.predict(X_plot), color='purple', label='Метод случайного леса')
plt.legend()
plt.show()
